{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.models import resnet18\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import time\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Define transforms and datasets\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize([224, 224]),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.Flowers102(root='./dataset', split='train', transform=train_transform, download=True)\n",
        "test_dataset = torchvision.datasets.Flowers102(root='./dataset', split='val', transform=test_transform, download=True)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, drop_last=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False, drop_last=False)\n",
        "\n",
        "# Initialize the model\n",
        "model = resnet18(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = torch.nn.Linear(num_ftrs, 102)  # Change the last layer for 102 classes\n",
        "\n",
        "# Define loss function, optimizer, and scheduler\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # Using Adam optimizer\n",
        "scheduler = StepLR(optimizer, step_size=5, gamma=0.1)  # StepLR scheduler\n",
        "\n",
        "# Train the model\n",
        "def train():\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, labels in train_dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    return total_loss / len(train_dataloader), correct / total\n",
        "\n",
        "# Test the model\n",
        "def test():\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_dataloader:\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    return correct / total\n",
        "\n",
        "\n",
        "def main():\n",
        "    best_acc = 0.0\n",
        "    epochs_without_improvement = 0\n",
        "    max_epochs_without_improvement = 10\n",
        "    epoch = 0\n",
        "    accuracy_threshold = 0.75\n",
        "    while True:\n",
        "        start_time = time.time()\n",
        "        train_loss, train_acc = train()\n",
        "        test_acc = test()\n",
        "        end_time = time.time()\n",
        "        epoch_duration = end_time - start_time\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}], Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}, Time: {epoch_duration:.2f}s\")\n",
        "        scheduler.step()\n",
        "\n",
        "        if test_acc > best_acc:\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "            best_acc = test_acc\n",
        "            epochs_without_improvement = 0\n",
        "        else:\n",
        "            epochs_without_improvement += 1\n",
        "\n",
        "        # Check if accuracy exceeds the threshold, and print Accuracy id >= 75%\n",
        "        if test_acc >= accuracy_threshold:\n",
        "            print(f\"Accuracy exceeds {round(test_acc * 100)}%! \\n\")\n",
        "\n",
        "        if epochs_without_improvement >= max_epochs_without_improvement:\n",
        "            print(\"Early stopping due to no improvement in validation accuracy\")\n",
        "            break\n",
        "\n",
        "        epoch+=1\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "9zt5hq9YFdyw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "061ea0b1-add1-4311-acd6-ee6c5bf5ab15",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1], Train Loss: 4.0585, Train Acc: 0.1396, Test Acc: 0.1049, Time: 90.96s\n",
            "Epoch [2], Train Loss: 2.6347, Train Acc: 0.3958, Test Acc: 0.2873, Time: 84.22s\n",
            "Epoch [3], Train Loss: 1.9788, Train Acc: 0.5135, Test Acc: 0.4059, Time: 83.75s\n",
            "Epoch [4], Train Loss: 1.6354, Train Acc: 0.6083, Test Acc: 0.5088, Time: 84.48s\n",
            "Epoch [5], Train Loss: 1.2681, Train Acc: 0.7021, Test Acc: 0.5843, Time: 84.88s\n",
            "Epoch [6], Train Loss: 0.9310, Train Acc: 0.7885, Test Acc: 0.7569, Time: 84.53s\n",
            "Accuracy exceeds 76%! \n",
            "\n",
            "Epoch [7], Train Loss: 0.7664, Train Acc: 0.8385, Test Acc: 0.7863, Time: 85.80s\n",
            "Accuracy exceeds 79%! \n",
            "\n",
            "Epoch [8], Train Loss: 0.6542, Train Acc: 0.8802, Test Acc: 0.7951, Time: 87.68s\n",
            "Accuracy exceeds 80%! \n",
            "\n",
            "Epoch [9], Train Loss: 0.6582, Train Acc: 0.8646, Test Acc: 0.8206, Time: 85.21s\n",
            "Accuracy exceeds 82%! \n",
            "\n",
            "Epoch [10], Train Loss: 0.5467, Train Acc: 0.9010, Test Acc: 0.8216, Time: 83.12s\n",
            "Accuracy exceeds 82%! \n",
            "\n",
            "Epoch [11], Train Loss: 0.5726, Train Acc: 0.9031, Test Acc: 0.8255, Time: 81.32s\n",
            "Accuracy exceeds 83%! \n",
            "\n",
            "Epoch [12], Train Loss: 0.5448, Train Acc: 0.8969, Test Acc: 0.8225, Time: 83.67s\n",
            "Accuracy exceeds 82%! \n",
            "\n",
            "Epoch [13], Train Loss: 0.5358, Train Acc: 0.9010, Test Acc: 0.8314, Time: 84.60s\n",
            "Accuracy exceeds 83%! \n",
            "\n"
          ]
        }
      ]
    }
  ]
}