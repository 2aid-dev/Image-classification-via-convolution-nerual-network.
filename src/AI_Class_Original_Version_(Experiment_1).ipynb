{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLhIcdNFgUWj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Build the transform for the train dataset and test dataset.\n",
        "train_transform = torchvision.transforms.Compose(\n",
        "    [torchvision.transforms.Resize([224, 224]),\n",
        "     torchvision.transforms.ToTensor()])\n",
        "\n",
        "test_transform = torchvision.transforms.Compose(\n",
        "    [torchvision.transforms.Resize([224, 224]), torchvision.transforms.ToTensor()])\n",
        "\n",
        "# Build the train dataset and test dataset\n",
        "train_dataset = torchvision.datasets.Flowers102(root='./dataset', split='train', transform=train_transform,\n",
        "                                                download=True)\n",
        "test_dataset = torchvision.datasets.Flowers102(root='./dataset', split='val', transform=test_transform,\n",
        "                                               download=True)\n",
        "\n",
        "# Build the train dataloader and test dataloader use the two datasets.\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True, drop_last=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=True, drop_last=True)\n",
        "\n",
        "# Build the Convolution Neural Network\n",
        "# But we can build the resnet18 easily by the torchvision:\n",
        "model = torchvision.models.resnet18(torchvision.models.ResNet18_Weights)\n",
        "\n",
        "# Build the loss function and optimizer\n",
        "# For the Image Classification task, we use the cross-entropy loss function as the loss function and use the SGD(Stochastic Gradient Descent) as the optimizer.\n",
        "\n",
        "\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.005, momentum=0.9)\n",
        "\n",
        "\n",
        "# Train the model\n",
        "def train():\n",
        "    all_loss = 0.0\n",
        "    n = 0\n",
        "    for data in train_dataloader:\n",
        "        n = n + 1\n",
        "        optimizer.zero_grad()  # Set 0 into grads of optimizer\n",
        "        image, target = data  # Fetch the data and target\n",
        "        output = model(image)  # Forward\n",
        "        loss = loss_function(output, target)  # Calculate the loss\n",
        "        loss.backward()  # Backward\n",
        "        optimizer.step()  # Optimizer works\n",
        "        all_loss += loss.item()\n",
        "        print('Train process: %.3f of this epoch, loss : %.2f ' % (n / len(train_dataloader), loss.item()))\n",
        "    return all_loss / len(train_dataloader)  # return the loss\n",
        "\n",
        "\n",
        "# Test the model\n",
        "def test():\n",
        "    model.eval()  # set the model into the evaluation mode, stopping Backward.\n",
        "    all_acc = 0.0\n",
        "    n = 0\n",
        "    for data in test_dataloader:\n",
        "        n = n + 1\n",
        "        image, target = data  # Fetch the data\n",
        "        output = model(image)  # Forward\n",
        "        print('Test process: %.2f of this epoch' % (n / len(test_dataloader)))\n",
        "        all_acc += torch.eq(torch.argmax(output, dim=-1), target).float().mean()  # Partial accuary\n",
        "    model.train()  # set the model into training mode\n",
        "    return all_acc / len(test_dataloader)\n",
        "\n",
        "\n",
        "def main():\n",
        "    best_acc = 0.0\n",
        "    for i in range(15):  # train for 15 epochs\n",
        "        # best accuary\n",
        "        loss = train()\n",
        "        acc = test()\n",
        "        print(f\"epoch: {i}, loss: {loss}, accuary: {acc}\")\n",
        "        if acc > best_acc:\n",
        "            torch.save(model, 'best.pth')  # save the best model\n",
        "            best_acc = acc\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    }
  ]
}